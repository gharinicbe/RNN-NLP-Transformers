{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c235f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\harinilearn\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\harinilearn\\lib\\site-packages (from SpeechRecognition) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\harinilearn\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\harinilearn\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\harinilearn\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\harinilearn\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.9.14)\n",
      "Requirement already satisfied: gTTS in c:\\harinilearn\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\harinilearn\\lib\\site-packages (from gTTS) (2.28.1)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\harinilearn\\lib\\site-packages (from gTTS) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\harinilearn\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\harinilearn\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\harinilearn\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\harinilearn\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\harinilearn\\lib\\site-packages (from requests<3,>=2.27->gTTS) (1.26.11)\n",
      "Requirement already satisfied: transformers in c:\\harinilearn\\lib\\site-packages (4.32.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\harinilearn\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\harinilearn\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\harinilearn\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\harinilearn\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\harinilearn\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: filelock in c:\\harinilearn\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in c:\\harinilearn\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\harinilearn\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\harinilearn\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\harinilearn\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "# To be able to convert text to Speech #(3.8.1)\n",
    "! pip install SpeechRecognition \n",
    "#To convey the Speech to text and also speak it out #(2.2.3)\n",
    "!pip install gTTS \n",
    "# To install our language model\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf34b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\harinilearn\\lib\\site-packages (4.32.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\harinilearn\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: requests in c:\\harinilearn\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\harinilearn\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\harinilearn\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\harinilearn\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\harinilearn\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\harinilearn\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in c:\\harinilearn\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\harinilearn\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\harinilearn\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\harinilearn\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\harinilearn\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125b1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speech-to-text\n",
    "import speech_recognition as sr\n",
    "# for text-to-speech\n",
    "from gtts import gTTS\n",
    "# for language model\n",
    "import transformers\n",
    "import os\n",
    "import time\n",
    "# for data\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1603d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\harinilearn\\lib\\site-packages (0.2.13)\n",
      "----- Starting up dev -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at microsoft/DialoGPT-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Me  -->  hello Dev hello Dev hello Dev\n",
      "Dev -->  Hello I am Dave the AI, what can I do for you?\n",
      "Listening...\n",
      "Me  -->  thank you for responding thank you for responding thank you for responding\n",
      "Dev -->  anytime!\n",
      "Listening...\n",
      "Me  -->  ERROR\n",
      "Dev -->  Sorry, come again?\n",
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me  -->  where are you from\n",
      "Dev -->  I'm from the UK\n",
      "Listening...\n",
      "Me  -->  exit exit\n",
      "Dev -->  Hope to meet soon\n",
      "----- Closing down Dev -----\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio\n",
    "\n",
    "# Building the AI\n",
    "class ChatBot():\n",
    "    def __init__(self, name):\n",
    "        print(\"----- Starting up\", name, \"-----\")\n",
    "        self.name = name\n",
    "    def speech_to_text(self):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.Microphone() as mic:\n",
    "            print(\"Listening...\")\n",
    "            audio = recognizer.listen(mic)\n",
    "            self.text=\"ERROR\"\n",
    "        try:\n",
    "            self.text = recognizer.recognize_google(audio)\n",
    "            print(\"Me  --> \", self.text)\n",
    "        except:\n",
    "            print(\"Me  -->  ERROR\")\n",
    "    @staticmethod\n",
    "    def text_to_speech(text):\n",
    "        print(\"Dev --> \", text)\n",
    "        speaker = gTTS(text=text, lang=\"en\", slow=False)\n",
    "        speaker.save(\"res.mp3\")\n",
    "        statbuf = os.stat(\"res.mp3\")\n",
    "        mbytes = statbuf.st_size / 1024\n",
    "        duration = mbytes / 200\n",
    "        os.system('start res.mp3')  #if you are using mac->afplay or else for windows->start\n",
    "        # os.system(\"close res.mp3\")\n",
    "        time.sleep(int(50*duration))\n",
    "        os.remove(\"res.mp3\")\n",
    "    def wake_up(self, text):\n",
    "        return True if self.name in text.lower() else False\n",
    "    @staticmethod\n",
    "    def action_time():\n",
    "        return datetime.datetime.now().time().strftime('%H:%M')\n",
    "# Running the AI\n",
    "if __name__ == \"__main__\":\n",
    "    ai = ChatBot(name=\"dev\")\n",
    "    nlp = transformers.pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\")\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "    ex=True\n",
    "    while ex:\n",
    "        ai.speech_to_text()\n",
    "        ## wake up\n",
    "        if ai.wake_up(ai.text) is True:\n",
    "            res = \"Hello I am Dave the AI, what can I do for you?\"\n",
    "        ## action time\n",
    "        elif \"time\" in ai.text:\n",
    "            res = ai.action_time()\n",
    "        ## respond politely\n",
    "        elif any(i in ai.text for i in [\"thank\",\"thanks\"]):\n",
    "            res = np.random.choice([\"you're welcome!\",\"anytime!\",\"no problem!\",\"cool!\",\"I'm here if you need me!\",\"mention not\"])\n",
    "        elif any(i in ai.text for i in [\"exit\",\"close\"]):\n",
    "            res = np.random.choice([\"Tata\",\"Have a good day\",\"Bye\",\"Goodbye\",\"Hope to meet soon\",\"peace out!\"])\n",
    "            ex=False\n",
    "        ## conversation\n",
    "        else:   \n",
    "            if ai.text==\"ERROR\":\n",
    "                res=\"Sorry, come again?\"\n",
    "            else:\n",
    "                chat = nlp(transformers.Conversation(ai.text), pad_token_id=50256)\n",
    "                res = str(chat)\n",
    "                res = res[res.find(\"bot >> \")+6:].strip()\n",
    "        ai.text_to_speech(res)\n",
    "    print(\"----- Closing down Dev -----\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae52d3",
   "metadata": {},
   "source": [
    "The line os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" sets an environment variable named TOKENIZERS_PARALLELISM to the value \"true\". This environment variable is related to the Hugging Face transformers library and specifically affects the parallelism behavior of the library when it comes to tokenization.\n",
    "\n",
    "The transformers library is commonly used for natural language processing tasks, including text tokenization for various NLP models. Setting TOKENIZERS_PARALLELISM can impact the speed and efficiency of tokenization processes, especially when dealing with large datasets or multiple processes.\n",
    "\n",
    "Here's what it does:\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\": This line sets the environment variable TOKENIZERS_PARALLELISM to the string value \"true\". The os.environ dictionary is used to manage environment variables in Python. In this case, the variable is being set to enable parallelism during tokenization.\n",
    "By setting TOKENIZERS_PARALLELISM to \"true\", you are instructing the transformers library to use parallel processing techniques during tokenization tasks. This can potentially improve the speed of tokenization by leveraging multiple CPU cores or threads to process different parts of the data simultaneously.\n",
    "\n",
    "Keep in mind that the effectiveness of parallelism can vary depending on the specific hardware and dataset you're working with. It's a good practice to benchmark and test different settings to determine the optimal configuration for your particular use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
